{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_extractive.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PKVs_--UgDCa",
        "s53PFrSvgH5Z",
        "DWkEJPwfgPr0"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IUqVARpoePU2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"A Christmas tree that can receive text messages has been unveiled at London's Tate Britain art gallery.\n",
        "\n",
        "The spruce has an antenna which can receive Bluetooth texts sent by visitors to the Tate. The messages will be \"unwrapped\" by sculptor Richard Wentworth, who is responsible for decorating the tree with broken plates and light bulbs. It is the 17th year that the gallery has invited an artist to dress their Christmas tree. Artists who have decorated the Tate tree in previous years include Tracey Emin in 2002.\n",
        "\n",
        "The plain green Norway spruce is displayed in the gallery's foyer. Its light bulb adornments are dimmed, ordinary domestic ones joined together with string. The plates decorating the branches will be auctioned off for the children's charity ArtWorks. Wentworth worked as an assistant to sculptor Henry Moore in the late 1960s. His reputation as a sculptor grew in the 1980s, while he has been one of the most influential teachers during the last two decades. Wentworth is also known for his photography of mundane, everyday subjects such as a cigarette packet jammed under the wonky leg of a table. \"\"\""
      ],
      "metadata": {
        "id": "hb2VIe1ZelKo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lemma\n",
        "def lemmatization_func(text:str) -> str:\n",
        "    tokenizer = ToktokTokenizer()\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens] \n",
        "    lemma_word = []\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    for w in tokens:\n",
        "        word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
        "        word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "        word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
        "        lemma_word.append(word3)\n",
        "    preprocessed_text = ' '.join(lemma_word)\n",
        "\n",
        "    return preprocessed_text"
      ],
      "metadata": {
        "id": "YvTG9LHFkc0e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stopWords = set(stopwords.words(\"english\"))\n",
        "lemma_text = lemmatization_func(text)\n",
        "words = word_tokenize(text)\n",
        "sentences = sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rrUkdxVf8S2",
        "outputId": "4db85cfc-aa20-4c3f-8204-a142227828dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Origin WordCount Method\n",
        "\n",
        "* [easy WordCount website link](https://www.mygreatlearning.com/blog/text-summarization-in-python/)"
      ],
      "metadata": {
        "id": "PKVs_--UgDCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqTable = dict()\n",
        "for word in words:\n",
        "  word = word.lower()\n",
        "  if word in stopWords:\n",
        "    continue\n",
        "  if word in freqTable:\n",
        "    freqTable[word] += 1\n",
        "  else:\n",
        "    freqTable[word] = 1\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "sentenceValue = dict()\n"
      ],
      "metadata": {
        "id": "QD5KH1v3gjpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  for word, freq in freqTable.items():\n",
        "    if word in sentence.lower():\n",
        "      if sentence in sentenceValue:\n",
        "        sentenceValue[sentence] += freq\n",
        "      else:\n",
        "        sentenceValue[sentence] = freq\n",
        "\n",
        "sumValues = 0\n",
        "for sentence in sentenceValue:\n",
        "  sumValues += sentenceValue[sentence]\n",
        "\n",
        "average = int(sumValues / len(sentenceValue))\n",
        "\n",
        "summary_origin_WordCount = ''\n",
        "for sentence in sentences:\n",
        "  if(sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
        "    summary_origin_WordCount += \" \" + sentence\n",
        "print(summary_origin_WordCount)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyigqfwlhdom",
        "outputId": "a53cf5a1-c2b9-4241-bee0-77d5f751c1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A Christmas tree that can receive text messages has been unveiled at London's Tate Britain art gallery. The messages will be \"unwrapped\" by sculptor Richard Wentworth, who is responsible for decorating the tree with broken plates and light bulbs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_origin_WordCount = summary_origin_WordCount"
      ],
      "metadata": {
        "id": "eNTExN0jJDWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.New WordCount Method\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s53PFrSvgH5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_freq_table(text_string):\n",
        "  words = word_tokenize(text_string)  \n",
        "  ps = PorterStemmer()\n",
        "  freq_table = {}\n",
        "  for word in words:\n",
        "      #stem word \n",
        "      word = ps.stem(word)\n",
        "      \n",
        "      #remove stopwords\n",
        "      if word in stopWords: \n",
        "        continue\n",
        "      elif word in freq_table:\n",
        "        freq_table[word] += 1\n",
        "      else:\n",
        "        freq_table[word] = 1\n",
        "          \n",
        "  return freq_table\n",
        "#freq_table = create_freq_table(\" \".join(sentences))"
      ],
      "metadata": {
        "id": "4cMa3j66gMYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_sentences(sentences, freq_table):\n",
        "  sentence_value = {}\n",
        "  for sentence in sentences:\n",
        "    word_count_in_sentence = len(word_tokenize(sentence))\n",
        "    for wordValue in freq_table:\n",
        "      if wordValue.lower() in sentence.lower():                \n",
        "        if sentence in sentence_value:\n",
        "          sentence_value[sentence] += freq_table[wordValue]\n",
        "        else:\n",
        "          sentence_value[sentence] = freq_table[wordValue]\n",
        "\n",
        "    sentence_value[sentence] = sentence_value[sentence] // word_count_in_sentence\n",
        "    \n",
        "  return sentence_value"
      ],
      "metadata": {
        "id": "xIRA0RaUh9Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_average_score(sentence_value):\n",
        "  sum_values = 0\n",
        "  for entry in sentence_value:\n",
        "    sum_values += sentence_value[entry]\n",
        "      \n",
        "  average = int(sum_values/len(sentence_value))\n",
        "  \n",
        "  return average"
      ],
      "metadata": {
        "id": "g2WGbjNRkE8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(sentences, sentence_value, threshold):\n",
        "  sentence_count = 0\n",
        "  summary = ''\n",
        "  for sentence in sentences:\n",
        "    if sentence in sentence_value and sentence_value[sentence] > threshold:\n",
        "      summary += \" \" + sentence\n",
        "      sentence_count += 1\n",
        "          \n",
        "  return summary"
      ],
      "metadata": {
        "id": "VBNP7qSckKzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "freq_table = create_freq_table(text)\n",
        "sentence_scores = score_sentences(sentences, freq_table)\n",
        "threshold = find_average_score(sentence_scores)\n",
        "summary_new_WordCount = generate_summary(sentences, sentence_scores, 1 * threshold)\n",
        "print(re.sub('\\n','',summary_new_WordCount))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPK-Rky7kUMB",
        "outputId": "e17b835a-f610-43f4-8afd-dad46fc266ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A Christmas tree that can receive text messages has been unveiled at London's Tate Britain art gallery. Artists who have decorated the Tate tree in previous years include Tracey Emin in 2002. The plates decorating the branches will be auctioned off for the children's charity ArtWorks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.TextRank with Sentence Embeddings"
      ],
      "metadata": {
        "id": "NTY4bx7hJR8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow.compat.v1 as tf\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "GeN-zpJsJ26n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embedding = embed(sentences)\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "tf.disable_v2_behavior()\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embedding)"
      ],
      "metadata": {
        "id": "YDoSz_hOJZg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate cosine similarity matrix\n",
        "sim_matrix = cosine_similarity(message_embeddings)\n",
        "#create graph and generate scores from pagerank algorithms\n",
        "nx_graph = nx.from_numpy_array(sim_matrix)\n",
        "scores = nx.pagerank(nx_graph)\n",
        "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "   \n",
        "num_of_sentences = 5\n",
        "    \n",
        "summary_sentence_embedding = \" \".join([i[1] for i in ranked_sentences[:num_of_sentences]])\n",
        "print(summary_sentence_embedding)"
      ],
      "metadata": {
        "id": "ZNhG72cKJ13Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca5d67f-4979-4ab7-bbc0-e8dc8b3c42d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Christmas tree that can receive text messages has been unveiled at London's Tate Britain art gallery. The messages will be \"unwrapped\" by sculptor Richard Wentworth, who is responsible for decorating the tree with broken plates and light bulbs. Artists who have decorated the Tate tree in previous years include Tracey Emin in 2002. It is the 17th year that the gallery has invited an artist to dress their Christmas tree. The spruce has an antenna which can receive Bluetooth texts sent by visitors to the Tate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Bert Extractive"
      ],
      "metadata": {
        "id": "or3us8G2O0AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-extractive-summarizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZqf_IZ_O5xu",
        "outputId": "3445873e-5672-4f9b-a421-e5bd9d1381f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-extractive-summarizer\n",
            "  Downloading bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (1.0.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer) (2.2.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (4.64.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (0.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (1.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->bert-extractive-summarizer) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->bert-extractive-summarizer) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (3.7.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->bert-extractive-summarizer) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->bert-extractive-summarizer) (3.0.9)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, bert-extractive-summarizer\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed bert-extractive-summarizer-0.10.1 huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVqEG6DpPbd9",
        "outputId": "71983e04-3f0f-414b-cc54-defaab15e610"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=48c7b4f0ab07b3b33934491427fb64b5a03f3cae999b899109f91cf7d489aded\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from summarizer import Summarizer\n",
        "model = Summarizer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G411i1xgO_iG",
        "outputId": "9e5f1c42-a9bc-4b2a-aa94-7182338fd7e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Christmas tree that can receive text messages has been unveiled at London's Tate Britain art gallery. The spruce has an antenna which can receive Bluetooth texts sent by visitors to the Tate. It is the 17th year that the gallery has invited an artist to dress their Christmas tree.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model(text)\n",
        "summary_bert = \"\".join(result)\n",
        "print(summary_bert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nmTar76QYan",
        "outputId": "70405509-2209-441d-beb6-a09a64f27b7d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Christmas tree that can receive text messages has been unveiled at London's Tate Britain art gallery. The spruce has an antenna which can receive Bluetooth texts sent by visitors to the Tate. It is the 17th year that the gallery has invited an artist to dress their Christmas tree.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric Evalutaion"
      ],
      "metadata": {
        "id": "DWkEJPwfgPr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "ROUGE = Rouge()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDKCg3E0idG8",
        "outputId": "d95060ec-df32-4d96-cba5-fd7bf8072bde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference=\"The messages will be 'unwrapped' by sculptor Richard Wentworth, who is responsible for decorating the tree with broken plates and light bulbs.A Christmas tree that can receive text messages has been unveiled at London's Tate Britain art gallery.It is the 17th year that the gallery has invited an artist to dress their Christmas tree.The spruce has an antenna which can receive Bluetooth texts sent by visitors to the Tate.His reputation as a sculptor grew in the 1980s, while he has been one of the most influential teachers during the last two decades.\"\n",
        "#candidate_new_WordCount = summary_new_WordCount\n"
      ],
      "metadata": {
        "id": "lxJ-USOHii1G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just see recall\n",
        "ROUGE.get_scores(summary_origin_WordCount, reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNltD7-AjLQB",
        "outputId": "83baf94a-04fd-49f9-b00e-4049127a1c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.6666666621622086,\n",
              "   'p': 0.972972972972973,\n",
              "   'r': 0.5070422535211268},\n",
              "  'rouge-2': {'f': 0.5384615343242604,\n",
              "   'p': 0.9210526315789473,\n",
              "   'r': 0.3804347826086957},\n",
              "  'rouge-l': {'f': 0.6666666621622086,\n",
              "   'p': 0.972972972972973,\n",
              "   'r': 0.5070422535211268}}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROUGE.get_scores(summary_new_WordCount, reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsQCb7Squ-ZL",
        "outputId": "3dca885b-e5f1-447a-98c5-b0093ed44b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.4642857096444516,\n",
              "   'p': 0.6341463414634146,\n",
              "   'r': 0.36619718309859156},\n",
              "  'rouge-2': {'f': 0.27737225836219304,\n",
              "   'p': 0.4222222222222222,\n",
              "   'r': 0.20652173913043478},\n",
              "  'rouge-l': {'f': 0.41071428107302305,\n",
              "   'p': 0.5609756097560976,\n",
              "   'r': 0.323943661971831}}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROUGE.get_scores(summary_sentence_embedding, reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "961ARDER-hen",
        "outputId": "67df12fb-3b2c-4bf5-8a55-0dd5f78db10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.7910447711372245,\n",
              "   'p': 0.8412698412698413,\n",
              "   'r': 0.7464788732394366},\n",
              "  'rouge-2': {'f': 0.7428571378703674,\n",
              "   'p': 0.7831325301204819,\n",
              "   'r': 0.7065217391304348},\n",
              "  'rouge-l': {'f': 0.7761193980028959,\n",
              "   'p': 0.8253968253968254,\n",
              "   'r': 0.7323943661971831}}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROUGE.get_scores(summary_bert, reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s30JNaK-QjE2",
        "outputId": "6679924d-44e7-4b7a-9617-4422b6b9529e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'rouge-1': {'f': 0.6851851806807271, 'p': 1.0, 'r': 0.5211267605633803},\n",
              "  'rouge-2': {'f': 0.6474820099125305,\n",
              "   'p': 0.9574468085106383,\n",
              "   'r': 0.4891304347826087},\n",
              "  'rouge-l': {'f': 0.6851851806807271, 'p': 1.0, 'r': 0.5211267605633803}}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}